= ReṼoman (Rev-Woman)
Gopal S Akshintala <gopalakshintala@gmail.com>
:Revision: 1.0
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
:toc:
:toc-placement!:
:sourcedir: src/main/kotlin
:testdir: src/integrationTest/java
:pmtemplates: src/integrationTest/resources/pm-templates
:imagesdir: docs/images
:prewrap!:
:revoman-version: 0.21.4

____

Re - Request/Response

Ṽ - Validation

____

'''


*ReVoman* is an API automation tool for JVM (Java/Kotlin) from the API-first SaaS company, Salesforce. It lets you execute a Postman collection in a JVM program/test.

'''

[.lead]
To start with, think of it as Postman for JVM (Java/Kotlin); that emulates this *Run* button on a collection through a Java program.
But it's even better

image::postman-run.png[]

[.lead]
It strikes a balance between _flexibility_ provided by low-level tools like link:https://rest-assured.io/[**REST Assured**] and _ease of use_ provided by UI tools like link:https://www.postman.com/[**Postman**]

image::hybrid-tool.png[]

== Artifacts

[.lead]
Maven
[source,xml,subs=attributes+]
----
<dependency>
  <groupId>com.salesforce.revoman</groupId>
  <artifactId>revoman</artifactId>
  <version>{revoman-version}</version>
</dependency>
----
[.lead]
Bazel
[source,bzl,subs=attributes+]
----
"com.salesforce.revoman:revoman"
----
[.lead]
Gradle Kts
[source,kts,subs=attributes+]
----
implementation("com.salesforce.revoman:revoman:{revoman-version}")
----

toc::[]

== Why ReVoman?

=== The Problem

* The majority of JVM SaaS applications are REST-based. But the API automation is done through a Mul-*T*-verse of Integration/Functional tests, E2E tests and Manual tests, each with its own frameworks, tools, and internal utilities, testing almost the same code flow.
* These custom alien automation frameworks, often built using low-level tools like link:https://rest-assured.io/[**REST Assured**] are specific to a service or domain and are rigid to reuse, extend and difficult to maintain.
* This automation competes on cognitive complexity and learning curve with the Prod code, and mostly, automation wins.
* After a point, the API automation may deviate from it's purpose of augmenting real end-user interaction and turns into a foot-chain for development.

image::cognitive-complexity.png[]

=== The Solution

* Contrary to custom frameworks, almost every team uses Postman for manual testing
* Postman collections contain a lot of information in a structured way, which when used can mitigate writing a lot of code

____

* How _productive_ would it be, if you can plug your exported Postman collection,
that you anyway would have created for your manual testing, and execute them through your JVM tests?

* How about a Universal API automation tool, promotes low-code and low-cognitive-complexity and strikes a balance between flexibility and ease of use

____


=== API automation with _ReṼoman_

Let’s check out how you can perform *Template-Driven-Testing* with ReVoman:

== API

=== Input

ReVoman has only one method `revUp` that you can supplying a config:

[source,java,indent=0,options="nowrap"]
----
ReVoman.revUp(
  Kick.configure()
    ...
    .off())
----

Let’s check out how to build this config with an example:

ifdef::env-github[]

[source,java,indent=0,options="nowrap"]
.link:{testdir}/com/salesforce/revoman/integration/core/pq/PQE2ETest.java[PQE2ETest.java, tag=pq-e2e-with-revoman-config-demo]
----
ReVoman.revUp( // <1>
  Kick.configure()
      .templatePaths(PQ_TEMPLATE_PATHS) // <2>
      .environmentPath("pm-templates/pq/pq-env.postman_environment.json") // <3>
      .dynamicEnvironment( // <4>
          Map.of(
              "$quoteFieldsToQuery", "LineItemCount, CalculationStatus",
              "$qliFieldsToQuery", "Id, Product2Id",
              "$qlrFieldsToQuery", "Id, QuoteId, MainQuoteLineId, AssociatedQuoteLineId"))
      .customDynamicVariable( // <5>
          "$quantity", ignore -> String.valueOf(Random.Default.nextInt(10) + 1))
      .requestConfig( // <6>
          unmarshallRequest(
              ASYNC_STEP_NAMES,
              PlaceQuoteInputRepresentation.class,
              adapter(PlaceQuoteInputRepresentation.class)))
      .hooks( // <7>
          pre(
              ASYNC_STEP_NAMES,
              (stepName, requestInfo, rundown) -> {
                final var pqInputRep =
                    requestInfo.<PlaceQuoteInputRepresentation>getTypedTxObj();
                assertThat(pqInputRep).isNotNull();
                if ("pq-create: qli+qlr (skip-pricing)"
                    .equals(pqInputRep.getGraph().getGraphId())) {
                  LOGGER.info("Skip pricing for step: {}", stepName);
                  rundown.mutableEnv.set("$pricingPref", PricingPref.Skip.toString());
                } else {
                  rundown.mutableEnv.set("$pricingPref", PricingPref.System.toString());
                }}),
          post("query-quote-and-related-records", PQE2ETest::assertAfterPQCreate),
          post(
              ASYNC_STEP_NAMES,
              (stepName, rundown) -> {
                LOGGER.info(
                    "Waiting after Step: {} for the Quote: {} to get processed",
                    stepName,
                    rundown.mutableEnv.getString("quoteId"));
                // ! CAUTION 10/09/23 gopala.akshintala: This test can be flaky until
                // polling is implemented
                Thread.sleep(20000);}))
      .haltOnAnyFailureExceptForSteps(STEPS_TO_IGNORE_FOR_FAILURE) // <8>
      .responseConfig( // <9>
          unmarshallSuccessResponse("quote-related-records", CompositeResponse.class),
          validateIfSuccess( // <9.1>
              ASYNC_STEP_NAMES,
              PlaceQuoteOutputRepresentation.class,
              validatePQSuccessResponse),
          validateIfFailed(
              FAILURE_STEP_NAMES,
              PlaceQuoteOutputRepresentation.class,
              validatePQErrorResponse))
      .insecureHttp(true) // <10>
      .off()); // Kick-off
----
<1> `revUp` is the method to call passing a configuration, built as below
<2> Supply the path (relative to resources) to the Template Collection JSON file
<3> Supply the path (relative to resources) to the Environment JSON file
<4> Supply any dynamic environment
<5> Plug Custom dynamic variables that are prepared at runtime
<6> You can provide a strong type for your request to be marshalled into. This shall be passed onto which executing pre-hooks
<7> You can set up a pre- / post-hook around a Step via `hooks`, which can help as callbacks, especially for Async operations.
** These runs despite the step are successful or failed. The entire rundown till that step shall be provided to the hook as a parameter
<8> It lets you be in charge of the Step Orchestration by letting you configure a pass-list of steps to ignore for failure
<9> Provide configuration to unmarshall/deserialize response JSON into strong types
** ReVoman supports all data types within or outside the core without any extra annotations.
** `unmarshallErrorResponse` can be used for error Types
<9.1> Supply your validations/assertions to be run on a step response
** You can leverage the power of https://github.com/salesforce-misc/Vador[*Vador*] to write config-driven validations and supply them to ReVoman `validateIfSuccess`.
** Because both these tools are from the same Development team, you should see homogeneous patterns and seamless Integration and support.
** `validateIfError` can be used for error Types
<10> [Not for Prod] Ignore Java cert issues when firing Http calls

endif::[]
ifndef::env-github[]

[source,java,indent=0,options="nowrap"]
.link:{testdir}/com/salesforce/revoman/integration/core/pq/PQE2ETest.java[PQE2ETest.java, tag=pq-e2e-with-revoman-config-demo]
----
include::{testdir}/com/salesforce/revoman/integration/core/pq/PQE2ETest.java[tag=pq-e2e-with-revoman-config-demo]
----
<1> `revUp` is the method to call passing a configuration, built as below
<2> Supply the path (relative to resources) to the Template Collection JSON file
<3> Supply the path (relative to resources) to the Environment JSON file
<4> Supply any dynamic environment
<5> Plug Custom dynamic variables that are prepared at runtime
<6> You can provide a strong type for your request to be marshalled into. This shall be passed onto which executing pre-hooks
<7> You can set up a pre- / post-hook around a Step via `hooks`, which can help as callbacks, especially for Async operations.
** These runs despite the step are successful or failed. The entire rundown till that step shall be provided to the hook as a parameter
<8> It lets you be in charge of the Step Orchestration by letting you configure a pass-list of steps to ignore for failure
<9> Provide configuration to unmarshall/deserialize response JSON into strong types
** ReVoman supports all data types within or outside the core without any extra annotations.
** `unmarshallErrorResponse` can be used for error Types
<9.1> Supply your validations/assertions to be run on a step response
** You can leverage the power of https://github.com/salesforce-misc/Vador[*Vador*] to write config-driven validations and supply them to ReVoman `validateIfSuccess`.
** Because both these tools are from the same Development team, you should see homogeneous patterns and seamless Integration and support.
** `validateIfError` can be used for error Types
<10> [Not for Prod] Ignore Java cert issues when firing Http calls

endif::[]

=== Output

After all this, you receive back a detailed Rundown of all the steps with all the Request-Response data.
You get Strong types for the ones you are interested in so that you can run more assertions on top of the run.

[source,kotlin,indent=0,options="nowrap"]
----
Rundown(
  stepNameToReport: Map<String, StepReport>,
  environment: PostmanEnvironment)

StepReport(
    val status: String,
    val requestInfo: Either<RequestFailure, TxInfo<Request>>?,
    val preHookFailure: PreHookFailure?,
    val responseInfo: Either<ResponseFailure, TxInfo<Response>>?,
    val postHookFailure: PostHookFailure?,
    val envSnapshot: PostmanEnvironment<Any?>
)
----

image:failure-hierarchy.png[Failure Hierarchy]

Here is what a debugger view of a Rundown looks like:

image:full-report.png[Rundown of all steps]

Along with all the environment:

image:mutable-env.png[Mutable environment after the execution completion]

This report has everything you need to know about what happened during each step execution,
along with environment snapshot during that step execution.

image:step-report.png[Step Report]

`Rundown` has many convenience methods to ease applying further assertions on top of it.

=== Type Safety with flexible JSON marshalling/serialization and unmarshalling/deserialization

* ReVoman internally uses a modern JSON library called link:https://github.com/square/moshi[**Moshi**]
* Tools like **REST Assured* which use **Jackson** to serialize/deserialize JSON and you need to add extra annotations (like `@JsonIgnore`) on top of your POJOs. But when you don't have control over the POJO source-code, this is not possible. ReVoman needs no extra annotations on POJOs.
* There may be POJO that inherit from legacy classes which are hard or impossible to serialize. ReVoman let's you serialize such a legacy POJO by letting you pass `typesToIgnoreForMarshalling`, where you can you filter-out these legacy classes.
* The payload may not map to POJO and you may need a custom adapter for Conversion. Moshi has it covered for you with its advanced adapter mechanism and ReVoman accepts Moshi adapters. ReVoman also comes bundled with JSON reader and writer utils to help build Moshi adapters.

TIP: Refer link:{testdir}/com/salesforce/revoman/integration/core/pq/adapters/ConnectInputRepWithGraphAdapter.java[ConnectInputRepWithGraphAdapter]
for an advanced adapter use-case

=== Low-code

____

*Here you go, an link:{testdir}/com/salesforce/revoman/integration/core/pq/PQE2ETest.java[E2E test]*

____

[.lead]
The above test has low-code and low in Cognitive Complexity and is Transparent.
Compared to a traditional Integration/Functional or E2E test, approximately, the amount of code needed is *89%* less using ReVoman.

== Postman collection on Git

* Now that ReVoman hooks these templates into auto-builds or CI/CD, they always stay up to date, otherwise, Yoda makes sure they are with TFs.
* The entire Postman collection guards each *check-in* in the form of a Test suite.
* Any day, you can find a Postman collection for every feature you need to test, right in your VCS. Developers can import these templates directly from VCS for manual testing. This comes in very handy during FF/RF/Cross team blitz.
* With ReVoman, you no more need a release task to keep your Postman collections up-to-date.

=== Perf

This entire execution of **70 steps**, which include **10 async steps**, took a mere *122 sec* on localhost.
This can be much better on auto-build environments.
(TBD: Capture the avg time taken on auto-builds)

image:pq-revoman-test-time.png[Localhost Test time on FTest console]

WARNING: ReVoman internally is very light-weight and the execution times are proportional
to how your server responds or your network speeds.

== Internal Orchestration

image::orchestration.png[ReVoman flow]

* It reads the environment JSON provided into in-memory.
* Then it reads and Inflates each static template in the collection, replacing variables at runtime from the in-memory environment
* It uses this information to Fire an HTTP request.
* It reads the response and executes Postscript JS on the response and updates the in-memory environment.
* It unmarshals the response into Strong JVM types as per the `responseConfig` supplied and lets you run *Type-safe* validations on the strong-type and fails-fast at first failure.
* Finally, if configured, the pre- /post-hook for the step gets triggered by passing the entire runDown
* The iteration continues for all the steps in the template collection

== Core Support

* First-class Salesforce core support
* Convert your persona-based Postman templates into JVM FTests and E2E tests that can be executed in auto-builds.
* Supports Steps involving Async operations

== Unified testing strategy

* Bring a *Unified &amp; Simplified Test strategy* across the mul-**T**-verse (FTests, E2E Tests, and Manual testing with Postman). This is a generic tool, and just by changing the template, the same config/pattern can be reused for any feature flow agnostic of it being an FTest or E2E test
* Transparency and better Traceability of issues
* This forces engineers to think like *API-first customers* while writing tests.
*FTest Data setup:* You can use the ReVoman for the FTest data setup too. This eliminates the need for different teams to write their own internal utilities for data setup.

== Future

[.lead]
The future looks bright

* *It's built with extensibility* in mind. It can easily be extended to support other template formats like *Kaiju*.
** You should be able to run Kaiju availability tests right from your IDE and debug them too

== FAQs

=== Is Debugging challenging with ReVoman?

* IDE debug points in the Prod code work as expected while running the test.
* Coming to FTest code, we debug when we don't understand what's going on in the code.
* Debugging necessarily doesn't have to be with a debug point in the IDE.
* To be able to debug, a developer needs to be informed about what went wrong and he/she should have ways to try and test an isolated portion of the run.
* In the case of ReVoman, you have the whole Postman collection at your disposal along with the Rundown. The entire test is transparent.
* This experience can be enhanced with more logging and better assertions.

=== Why not use https://learning.postman.com/docs/collections/using-newman-cli/command-line-integration-with-newman[Newman] or https://learning.postman.com/docs/postman-cli/postman-cli-overview/#comparing-the-postman-cli-and-newman[Postman CLI]?

* ReVoman may be similar to Newman or Postman CLI when it comes to executing a Postman collection, but the _similarities end there_.
* Newman/Postman CLI are built for node cannot be executed within a JVM. Even if you are able to run with some hacky way, there is no easy way to assert results.
* ReVoman is JVM first that lets you configure a lot more, and gives you back a detailed report to assert in a typesafe way
* Newman is limited and cannot be integrated into our automation model on JVM

== link:CONTRIBUTING.adoc[🙌🏼Wanna Collab & Contribute?]
